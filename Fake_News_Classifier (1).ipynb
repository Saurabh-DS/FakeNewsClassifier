{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fake News Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITreKaNoRZMY"
      },
      "source": [
        "from wordcloud import WordCloud, STOPWORDS \n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd #data processing\n",
        "\n",
        "import os\n",
        "import re\n",
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBxSx9pCRkh-"
      },
      "source": [
        "train=pd.read_csv('/content/drive/MyDrive/NLP-FakeNews/train.csv')\n",
        "test=pd.read_csv('/content/drive/MyDrive/NLP-FakeNews/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "bLv8KQaz-G67",
        "outputId": "cf4444cb-adbb-4d6d-a371-daefea70a4a3"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>Darrell Lucus</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
              "      <td>Daniel J. Flynn</td>\n",
              "      <td>Ever get the feeling your life circles the rou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Why the Truth Might Get You Fired</td>\n",
              "      <td>Consortiumnews.com</td>\n",
              "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
              "      <td>Jessica Purkiss</td>\n",
              "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
              "      <td>Howard Portnoy</td>\n",
              "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ... label\n",
              "0   0  ...     1\n",
              "1   1  ...     0\n",
              "2   2  ...     1\n",
              "3   3  ...     1\n",
              "4   4  ...     1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "_kEvRqcL-KYP",
        "outputId": "31e36813-7829-4067-875f-a4ceaa21f942"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20800</td>\n",
              "      <td>Specter of Trump Loosens Tongues, if Not Purse...</td>\n",
              "      <td>David Streitfeld</td>\n",
              "      <td>PALO ALTO, Calif.  —   After years of scorning...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20801</td>\n",
              "      <td>Russian warships ready to strike terrorists ne...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Russian warships ready to strike terrorists ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20802</td>\n",
              "      <td>#NoDAPL: Native American Leaders Vow to Stay A...</td>\n",
              "      <td>Common Dreams</td>\n",
              "      <td>Videos #NoDAPL: Native American Leaders Vow to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20803</td>\n",
              "      <td>Tim Tebow Will Attempt Another Comeback, This ...</td>\n",
              "      <td>Daniel Victor</td>\n",
              "      <td>If at first you don’t succeed, try a different...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20804</td>\n",
              "      <td>Keiser Report: Meme Wars (E995)</td>\n",
              "      <td>Truth Broadcast Network</td>\n",
              "      <td>42 mins ago 1 Views 0 Comments 0 Likes 'For th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ...                                               text\n",
              "0  20800  ...  PALO ALTO, Calif.  —   After years of scorning...\n",
              "1  20801  ...  Russian warships ready to strike terrorists ne...\n",
              "2  20802  ...  Videos #NoDAPL: Native American Leaders Vow to...\n",
              "3  20803  ...  If at first you don’t succeed, try a different...\n",
              "4  20804  ...  42 mins ago 1 Views 0 Comments 0 Likes 'For th...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfe0X05191aZ",
        "outputId": "ccbce5b4-4a4c-47da-c977-749db536630d"
      },
      "source": [
        "print(train.shape, test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20800, 5) (5200, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3pPCHsl91dR",
        "outputId": "866dcab1-a21f-40b2-b77c-4d495c46a341"
      },
      "source": [
        "print('-------------Train Data-------------')\n",
        "print(train.isnull().sum())\n",
        "print('-------------Test Data-------------')\n",
        "print(test.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------Train Data-------------\n",
            "id           0\n",
            "title      558\n",
            "author    1957\n",
            "text        39\n",
            "label        0\n",
            "dtype: int64\n",
            "-------------Test Data-------------\n",
            "id          0\n",
            "title     122\n",
            "author    503\n",
            "text        7\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IQVdZz591gP"
      },
      "source": [
        "test=test.dropna()\n",
        "train=train.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXjJFMeJ-ntr",
        "outputId": "599ff656-c8b3-449b-ed82-28f652c90e13"
      },
      "source": [
        "print(train.shape, test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18285, 5) (4575, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWLz56QI91ix"
      },
      "source": [
        "train['total']=train['title']+' '+train['author']+train['text']\n",
        "test['total']=test['title']+' '+test['author']+test['text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34m1UHFF-U95",
        "outputId": "80bc9bc5-c79d-44be-d8a2-77cbe279a752"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQn5arPd91lh",
        "outputId": "66747f26-6475-48eb-b8c4-819b143c854c"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer=WordNetLemmatizer()\n",
        "for index,row in train.iterrows():\n",
        "    filter_sentence = ''\n",
        "    \n",
        "    sentence = row['total']\n",
        "    sentence = re.sub(r'[^\\w\\s]','',sentence) #cleaning\n",
        "    \n",
        "    words = nltk.word_tokenize(sentence) #tokenization\n",
        "    \n",
        "    words = [w for w in words if not w in stop_words]  #stopwords removal\n",
        "    \n",
        "    for word in words:\n",
        "        filter_sentence = filter_sentence + ' ' + str(lemmatizer.lemmatize(word)).lower()\n",
        "        \n",
        "    train.loc[index,'total'] = filter_sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5M3x1dW-Ujg"
      },
      "source": [
        "train = train[['total','label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcftkJhz-Umi"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRkM2lVU91op"
      },
      "source": [
        "X_train = train['total']\n",
        "Y_train = train['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzGLhLKpsUZ9"
      },
      "source": [
        "# def vectorize_text(features, max_features):\n",
        "#     vectorizer = TfidfVectorizer( stop_words='english',\n",
        "#                             decode_error='strict',\n",
        "#                             analyzer='word',\n",
        "#                             ngram_range=(1, 2),\n",
        "#                             max_features=max_features\n",
        "#                             #max_df=0.5 # Verwendet im ML-Kurs unter Preprocessing                   \n",
        "#                             )\n",
        "#     feature_vec = vectorizer.fit_transform(features)\n",
        "#     return feature_vec.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7bgB92YsUj7"
      },
      "source": [
        "#Feature extraction using count vectorization and tfidf.\n",
        "count_vectorizer = CountVectorizer()\n",
        "count_vectorizer.fit_transform(X_train)\n",
        "freq_term_matrix = count_vectorizer.transform(X_train)\n",
        "tfidf = TfidfTransformer(norm=\"l2\")\n",
        "tfidf.fit(freq_term_matrix)\n",
        "tf_idf_matrix = tfidf.fit_transform(freq_term_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUmJmXQXsUmc",
        "outputId": "4d8f6336-abd9-45d1-fc29-c54f3b7634ed"
      },
      "source": [
        "tf_idf_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<18285x195357 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 5529540 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtV29XsvsUpy"
      },
      "source": [
        "test_counts = count_vectorizer.transform(test['total'].values)\n",
        "test_tfidf = tfidf.transform(test_counts)\n",
        "\n",
        "#split in samples\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(tf_idf_matrix, Y_train, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKeUBZh9sUtg",
        "outputId": "a92846c1-3fff-4879-f47c-46b0a8dc97a2"
      },
      "source": [
        "import sklearn.linear_model as sk\n",
        "logreg = sk.LogisticRegression(C=1e5)\n",
        "logreg.fit(X_train, y_train)\n",
        "pred = logreg.predict(X_test)\n",
        "print('Accuracy of Lasso classifier on training set: {:.2f}'\n",
        "     .format(logreg.score(X_train, y_train)))\n",
        "print('Accuracy of Lasso classifier on test set: {:.2f}'\n",
        "     .format(logreg.score(X_test, y_test)))\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "cm = confusion_matrix(y_test, pred)\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Lasso classifier on training set: 1.00\n",
            "Accuracy of Lasso classifier on test set: 0.98\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2533,   50],\n",
              "       [  50, 1939]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyjodXtRsUwP",
        "outputId": "6e5767e3-3569-4ac5-f8bb-abedb2da57e9"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "NB = MultinomialNB()\n",
        "NB.fit(X_train, y_train)\n",
        "pred = NB.predict(X_test)\n",
        "print('Accuracy of NB  classifier on training set: {:.2f}'\n",
        "     .format(NB.score(X_train, y_train)))\n",
        "print('Accuracy of NB classifier on test set: {:.2f}'\n",
        "     .format(NB.score(X_test, y_test)))\n",
        "cm = confusion_matrix(y_test, pred)\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of NB  classifier on training set: 0.77\n",
            "Accuracy of NB classifier on test set: 0.73\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2581,    2],\n",
              "       [1229,  760]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7AOzcEKxjfq"
      },
      "source": [
        "#pipeline\n",
        "#Assiging the variables again as once transformed vectors can't be transformed again using pipeline.\n",
        "X_train = train['total']\n",
        "Y_train = train['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53Zh0jKYxjil"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "from sklearn import linear_model\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no2kmrTcxjll"
      },
      "source": [
        "pipeline = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer(norm='l2')),\n",
        "    ('clf', linear_model.LogisticRegression(C=1e5)),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgX1qdAGxjs4",
        "outputId": "dec02bd4-b100-4b17-fba7-73e05ec89b07"
      },
      "source": [
        "pipeline.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=Non...\n",
              "                ('tfidf',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('clf',\n",
              "                 LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Co-FA_wmxjvl",
        "outputId": "5f3e4598-1953-4b8b-cd4a-48da0a806e18"
      },
      "source": [
        "pipeline.predict([\"2\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aR-mlHpUxvO4",
        "outputId": "9748bb27-e5c3-46e3-ff08-54045764c064"
      },
      "source": [
        "#saving the pipeline\n",
        "filename = 'pipeline.sav'\n",
        "joblib.dump(pipeline, '/content/drive/MyDrive/NLP-FakeNews/pipeline.sav')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/NLP-FakeNews/pipeline.sav']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG51Tcnh7BMt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d06b1ea7-391e-40c1-dc63-08fa79d5f358"
      },
      "source": [
        "loaded_model = joblib.load('/content/drive/MyDrive/NLP-FakeNews/pipeline.sav')\n",
        "result = loaded_model.predict([\"flynn hillary clinton big woman campus breitbart daniel j flynnever get feeling life circle roundabout rather head straight line toward intended destination hillary clinton remains big woman campus leafy liberal wellesley massachusetts everywhere else vote likely inauguration dress remainder day way miss havisham forever wore wedding dress speaking great expectations hillary rodham overflowed 48 year ago first addressed wellesley graduating class the president college informed gathered 1969 student needed debate far i could ascertain spokesman kind like democratic primary 2016 minus term unknown even seven sisters school i glad miss adams made clear i speaking today u 400 u miss rodham told classmate after appointing edger bergen charlie mccarthys mortimer snerds attendance bespectacled granny glass awarding matronly wisdom least john lennon wisdom took issue previous speaker despite becoming first win election seat u s senate since reconstruction edward brooke came criticism calling empathy goal protestors criticized tactic though clinton senior thesis saul alinsky lamented black power demagogue elitist arrogance repressive intolerance within new left similar word coming republican necessitated brief rebuttal trust rodham ironically observed 1969 one word i asked class rehearsal wanted say everyone came said talk trust talk lack trust u way feel others talk trust bust what say what say feeling permeates generation perhaps even understood distrusted the trust bust certainly busted clintons 2016 plan she certainly even understand people distrusted after whitewater travelgate vast conspiracy benghazi missing email clinton found distrusted voice friday there load compromising road broadening political horizon and distrust american people trump edged 48 percent 38 percent question immediately prior novembers election stood major reason closing horizon clinton described vanquisher supporter embracing lie con alternative fact assault truth reason she failed explain american people chose lie truth as history major among today know well people power invent fact attack question mark beginning end free society offered that hyperbole like many people emerge 1960s hillary clinton embarked upon long strange trip from high school goldwater girl wellesley college republican president democratic politician clinton drank time place gave degree more significantly went idealist cynic comparison two wellesley commencement address show way back lamented long leader viewed politics art possible challenge practice politics art making appears impossible possible now big woman campus odd woman white house wonder current station even possible why arent i 50 point ahead asked september in may asks isnt president the woman famously dubbed congenital liar bill safire concludes lie mind getting stood election day like finding jilted bride wedding day inspires dangerous delusion\"])\n",
        "print(result) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RknY2PvxxhZZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqV68oUCuYEP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YqkdM-IxiEO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr3yHNBGxiIF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J10opx1fxiLd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRI0HRwbuYHp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3calWhvsU2O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIekP-UzsU4u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrGmvcnlsU8o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8py2E0j_SVKu"
      },
      "source": [
        "## Get the Independent Features\n",
        "X=df.drop('label',axis=1)\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "misRlNCQSVPT"
      },
      "source": [
        "## Get the Dependent features\n",
        "y=df['label']\n",
        "y.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YJR1KeWSVSX"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZu7rWBUSVN9"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGutPKUQSVJh"
      },
      "source": [
        "\n",
        "df=df.dropna()\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_6hGVM7SVIM"
      },
      "source": [
        "messages=df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS86VF6HSVC9"
      },
      "source": [
        "messages.reset_index(inplace=True)\n",
        "messages.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40_lREUBSno5"
      },
      "source": [
        "messages['text'][6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CEJHwfHSnrb"
      },
      "source": [
        "#stemming\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import re\n",
        "ps = PorterStemmer()\n",
        "corpus = []\n",
        "for i in range(0, len(messages)):\n",
        "    review = re.sub('[^a-zA-Z]', ' ', messages['text'][i])\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    \n",
        "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
        "    review = ' '.join(review)\n",
        "    corpus.append(review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6LiY8-TSnyP"
      },
      "source": [
        "corpus[3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvuJ-gmO-sUc"
      },
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0B5caGh-w9a"
      },
      "source": [
        "sentences = nltk.sent_tokenize(paragraph)\n",
        "lemmatizer = WordNetLemmatizer()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czbuhf44-zKc"
      },
      "source": [
        "# Lemmatization\n",
        "for i in range(len(sentences)):\n",
        "    words = nltk.word_tokenize(sentences[i])\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
        "    sentences[i] = ' '.join(words)      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKfdjuDESnwE"
      },
      "source": [
        "\n",
        "## TFidf Vectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_v=TfidfVectorizer(max_features=5000,ngram_range=(1,3))\n",
        "X=tfidf_v.fit_transform(corpus).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWwDnz1qSnvA"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJaCOJhFS3kL"
      },
      "source": [
        "y=messages['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O3PU-wdS3ne"
      },
      "source": [
        "## Divide the dataset into Train and Test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqYOvicUS3qT"
      },
      "source": [
        "tfidf_v.get_feature_names()[:20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45nVNXb-S3uA"
      },
      "source": [
        "tfidf_v.get_params()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-ekxLS1S30B"
      },
      "source": [
        "count_df = pd.DataFrame(X_train, columns=tfidf_v.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tym2mcmpTDbS"
      },
      "source": [
        "count_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmSIuKNUTDeV"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqZ8RRLDTDjm"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    See full source and example: \n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "    \n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLFmHGMATDiI"
      },
      "source": [
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "classifier=MultinomialNB()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSLUSsfFTOCn"
      },
      "source": [
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "import itertools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjWQOkJeTOFF"
      },
      "source": [
        "\n",
        "classifier.fit(X_train, y_train)\n",
        "pred = classifier.predict(X_test)\n",
        "score = metrics.accuracy_score(y_test, pred)\n",
        "print(\"accuracy:   %0.3f\" % score)\n",
        "cm = metrics.confusion_matrix(y_test, pred)\n",
        "plot_confusion_matrix(cm, classes=['FAKE', 'REAL'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gptWvRoZTOMh"
      },
      "source": [
        "classifier.fit(X_train, y_train)\n",
        "pred = classifier.predict(X_test)\n",
        "score = metrics.accuracy_score(y_test, pred)\n",
        "score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pChVGAchTOKT"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0f0KJCVTOIn"
      },
      "source": [
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "linear_clf = PassiveAggressiveClassifier(n_iter=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Klp8UqF4TTXm"
      },
      "source": [
        "linear_clf.fit(X_train, y_train)\n",
        "pred = linear_clf.predict(X_test)\n",
        "score = metrics.accuracy_score(y_test, pred)\n",
        "print(\"accuracy:   %0.3f\" % score)\n",
        "cm = metrics.confusion_matrix(y_test, pred)\n",
        "plot_confusion_matrix(cm, classes=['FAKE Data', 'REAL Data'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4OYvE6MTbK5"
      },
      "source": [
        "Multinomial Classifier with Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgSueUKwTTdG"
      },
      "source": [
        "\n",
        "classifier=MultinomialNB(alpha=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqeKQc6MTTbd"
      },
      "source": [
        "\n",
        "previous_score=0\n",
        "for alpha in np.arange(0,1,0.1):\n",
        "    sub_classifier=MultinomialNB(alpha=alpha)\n",
        "    sub_classifier.fit(X_train,y_train)\n",
        "    y_pred=sub_classifier.predict(X_test)\n",
        "    score = metrics.accuracy_score(y_test, y_pred)\n",
        "    if score>previous_score:\n",
        "        classifier=sub_classifier\n",
        "    print(\"Alpha: {}, Score : {}\".format(alpha,score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QLPVYdtTe3x"
      },
      "source": [
        "## Get Features names\n",
        "feature_names = cv.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GuhhJq7Te88"
      },
      "source": [
        "classifier.coef_[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9esVGkCTfAc"
      },
      "source": [
        "### Most real\n",
        "sorted(zip(classifier.coef_[0], feature_names), reverse=True)[:20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yjj-mY_UTe6d"
      },
      "source": [
        "\n",
        "### Most fake\n",
        "sorted(zip(classifier.coef_[0], feature_names))[:5000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcLXH022UPA5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-8jIl7rUPF1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyQQoRCNUPPj"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ig_uWrjgUPN2"
      },
      "source": [
        "tf.__version__\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAQzWkb2UPLF"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWw1LgplUPJS"
      },
      "source": [
        "### Vocabulary size\n",
        "voc_size=5000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GXcZjsLUPDv"
      },
      "source": [
        "messages=X.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OgOky1cUXdS"
      },
      "source": [
        "messages['title'][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjXVOxfxUXn3"
      },
      "source": [
        "messages.reset_index(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1miCrc65UXll"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG7sj-Y0UXip"
      },
      "source": [
        "\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYNdN17CUXg6"
      },
      "source": [
        "### Dataset Preprocessing\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "corpus = []\n",
        "for i in range(0, len(messages)):\n",
        "    print(i)\n",
        "    review = re.sub('[^a-zA-Z]', ' ', messages['title'][i])\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    \n",
        "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
        "    review = ' '.join(review)\n",
        "    corpus.append(review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpqDTgYoUi6a"
      },
      "source": [
        "corpus[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAT6TITEUk-x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZPFm71KUozo"
      },
      "source": [
        "\n",
        "Embedding Representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfPvp0SGUpLQ"
      },
      "source": [
        "sent_length=20\n",
        "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
        "print(embedded_docs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF0_7amdUsKZ"
      },
      "source": [
        "embedded_docs[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFxhTo-0UuXQ"
      },
      "source": [
        "\n",
        "## Creating model\n",
        "embedding_vector_features=40\n",
        "model=Sequential()\n",
        "model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oINiZacwUvX6"
      },
      "source": [
        "\n",
        "len(embedded_docs),y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMlK5cCNUvdi"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "X_final=np.array(embedded_docs)\n",
        "y_final=np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqcYeqYAUvh8"
      },
      "source": [
        "X_final.shape,y_final.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKWvfcxJUvbV"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iTzjyxPU1U6"
      },
      "source": [
        "\n",
        "### Finally Training\n",
        "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOYMu04vU1f_"
      },
      "source": [
        "## Creating model\n",
        "embedding_vector_features=40\n",
        "model=Sequential()\n",
        "model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ps3ec8gaU1dP"
      },
      "source": [
        "y_pred=model.predict_classes(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ngKmw8vU1aP"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGrs8DJzU1YE"
      },
      "source": [
        "confusion_matrix(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2bezAf0Uubg"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}